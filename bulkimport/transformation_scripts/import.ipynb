{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SORT ACCORDING TO COLUMN\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "data = csv.reader(open('../INPUT_data/publishers.csv'))\n",
    "sortedlist = sorted(data, key=operator.itemgetter(1))    # 1 specifies according to first column we want to sort\n",
    "#now write the sorte result into new CSV file\n",
    "with open(\"../INPUT_data/publishers_sorted.csv\", \"w\") as f:\n",
    "  fileWriter = csv.writer(f, delimiter=',')\n",
    "  for row in sortedlist:\n",
    "      fileWriter.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PUBLISHERS\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "reader=csv.reader(open('../INPUT_data/publishers_sorted.csv', 'r'), delimiter=',')\n",
    "writer=csv.writer(open('../INPUT_data/publishers_sorted_distinct.csv', 'w'), delimiter=',')\n",
    "entries = set()\n",
    "\n",
    "for row in reader:\n",
    "   key = (row[0], row[1]) # instead of just the last name\n",
    "\n",
    "   if key not in entries:\n",
    "      writer.writerow(row)\n",
    "      entries.add(key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espadini/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PERIODICALS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/periodicals.csv\"\n",
    "file_name_output = \"../INPUT_data/periodicals_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espadini/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA AUTHORS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/authors.csv\"\n",
    "file_name_output = \"../INPUT_data/authors_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTHORS distinguish name and surname\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct.csv')\n",
    "o = open('../INPUT_data/authors_distinct_surname_name2.csv', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "writer = csv.writer(o, quoting=csv.QUOTE_ALL)\n",
    "for row in data[1:]:\n",
    "    author = row[0]\n",
    "    surname = author.partition(' ')[2] \n",
    "    name = author.partition(' ')[0]\n",
    "    new_author = [surname, name]\n",
    "    writer.writerow([new_author])\n",
    "\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### READ THE CSV (just to check)\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "for row in data[1:]:\n",
    "    \n",
    "    if (row[0] == ''):\n",
    "        print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PUBLISHERS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    publisherLocation = row[0] \n",
    "    publisherName = row[1]\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    publisherHasLocationNS = ET.QName(NS_ROUD, \"publisherHasLocation\")\n",
    "    publisherHasNameNS = ET.QName(NS_ROUD, \"publisherHasName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Publisher = ET.Element(PublisherNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Publisher, labelNS)\n",
    "    label.text = \"edi_\"+publisherName\n",
    "    \n",
    "    ## if row is empty, don't create element, otherwise the import will fail (of course only for properties that are not mandatory)\n",
    "    if (row[0] == ''):\n",
    "        print()\n",
    "    else:\n",
    "        publisherHasLocation = ET.SubElement(Publisher, publisherHasLocationNS, attrib={'knoraType':'richtext_value'})\n",
    "        publisherHasLocation.text = publisherLocation ## use variable defined with location of the publisher corresponding to first row\n",
    "    \n",
    "    publisherHasName = ET.SubElement(Publisher, publisherHasNameNS, attrib={'knoraType':'richtext_value'})\n",
    "    publisherHasName.text = publisherName  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Publisher, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PERIODICALS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/periodicals_distinct.csv')\n",
    "o = open('../OUTPUT_xml/periodicals.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    periodicalTitle = row[0] \n",
    "    labelPeriodicalTitle = row[0].replace('\"', '')  ## in label \" not accepted\n",
    "    word_list = re.split(', |\\(|/', labelPeriodicalTitle) ## split at comma, parenthesis or slash and take the first part (take the first part is below), using labelPeriodicalTitle where quotes have been already deleted\n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  ## replace accent with space and replace comma with nothing and split words\n",
    "    words = '_'.join(word_list) \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    periodicalHasTitleNS = ET.QName(NS_ROUD, \"periodicalHasTitle\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Periodical = ET.Element(PeriodicalNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Periodical, labelNS)\n",
    "    label.text = \"period_\"+labelPeriodicalTitle\n",
    "    periodicalHasTitle = ET.SubElement(Periodical, periodicalHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    periodicalHasTitle.text = periodicalTitle  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Periodical, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (AUTHORS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct_surname_name.csv')\n",
    "o = open('../OUTPUT_xml/authors.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    surname = row[1]\n",
    "    name = row[0]\n",
    "    #### for building id\n",
    "    if len(surname.split()) > 1:  ## if long name and surname\n",
    "        surnameid = '_'.join(re.split(' ', surname))\n",
    "    else:\n",
    "        surnameid = surname\n",
    "    if len(name.split()) > 1:\n",
    "        nameid = '_'.join(re.split(' ', name))\n",
    "    else:\n",
    "        nameid = name\n",
    "    if (row[0] == ''):  ## if author has only surname\n",
    "        authorid = (surnameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '') \n",
    "    else:\n",
    "        authorid = (surnameid+'_'+nameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '') \n",
    "   \n",
    "\n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    AuthorHasFamilyNameNS = ET.QName(NS_ROUD, \"authorHasFamilyName\")\n",
    "    AuthorHasGivenNameNS = ET.QName(NS_ROUD, \"authorHasGivenName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Author = ET.Element(AuthorNS, attrib={'id':authorid}) \n",
    "    label = ET.SubElement(Author, labelNS)\n",
    "    if (row[0] == ''):  ## if author has surname and name\n",
    "        label.text = \"aut_\"+surname\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "    else:\n",
    "        label.text = \"aut_\"+surname+\" \"+name\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "        authorHasGivenName = ET.SubElement(Author, AuthorHasGivenNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasGivenName.text = name  ## \n",
    "    \n",
    "    tree = ET.tostring(Author, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (ARTICLES)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/articles.csv')\n",
    "o = open('../OUTPUT_xml/articles.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 1000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> isPublishedInPeriodical\n",
    "    periodicalTitle = row[4].replace('\"', '')  ## all this copied from transformation to periodical above\n",
    "    word_list = re.split(', |\\(|/', periodicalTitle) \n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  \n",
    "    PeriodicalTarget = '_'.join(word_list) \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> IsInPeriodicalIssue\n",
    "    IsInPeriodicalIssueVolume = row[7]\n",
    "    if (',' in row[7]):\n",
    "        IsInPeriodicalIssue_split = re.split(', ',row[7])\n",
    "        IsInPeriodicalIssue = IsInPeriodicalIssue_split[0]\n",
    "        IsInPeriodicalVolume = IsInPeriodicalIssue_split[1].replace('-', ' et ')\n",
    "    else:\n",
    "        IsInPeriodicalVolumeOnly = row[7].replace('-', ' et ')\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> periodicalArticleIsInPages\n",
    "    PeriodicalArticleIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "        PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != ''):\n",
    "            PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+PeriodicalTarget\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "                PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "            else:\n",
    "                if (ArticleAuthor != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                    PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "                else:\n",
    "                    if (PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                        PeriodicalArticleLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "\n",
    "    PeriodicalArticleLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", PeriodicalArticleLabelComplete)\n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    PeriodicalArticleNS = ET.QName(NS_ROUD, \"PeriodicalArticle\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    isPublishedInPeriodicalNS = ET.QName(NS_ROUD, \"isPublishedInPeriodical\")\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    isInPeriodicalIssueNS = ET.QName(NS_ROUD, \"isInPeriodicalIssue\")\n",
    "    isInPeriodicalVolumeNS = ET.QName(NS_ROUD, \"isInPeriodicalVolume\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    periodicalArticleIsInPagesNS = ET.QName(NS_ROUD, \"periodicalArticleIsInPages\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    PeriodicalArticle = ET.Element(PeriodicalArticleNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(PeriodicalArticle, labelNS)\n",
    "    label.text = PeriodicalArticleLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(PeriodicalArticle, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(PeriodicalArticle, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInPeriodicalVolume  and  isInPeriodicalIssue\n",
    "    if (IsInPeriodicalIssueVolume != '' and IsInPeriodicalVolumeOnly == ''):\n",
    "        isInPeriodicalIssue = ET.SubElement(PeriodicalArticle, isInPeriodicalIssueNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalIssue.text = IsInPeriodicalIssue\n",
    "        isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalVolume.text = IsInPeriodicalVolume\n",
    "    else:   \n",
    "        if (IsInPeriodicalIssueVolume != ''):\n",
    "            isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "            isInPeriodicalVolume.text = IsInPeriodicalVolumeOnly\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isPublishedInPeriodical\n",
    "    isPublishedInPeriodical = ET.SubElement(PeriodicalArticle, isPublishedInPeriodicalNS)\n",
    "    Periodical = ET.SubElement(isPublishedInPeriodical, PeriodicalNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PeriodicalTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(PeriodicalArticle, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> periodicalArticleIsInPages\n",
    "    if (PeriodicalArticleIsInPages != ''):\n",
    "        periodicalArticleIsInPages = ET.SubElement(PeriodicalArticle, periodicalArticleIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        periodicalArticleIsInPages.text = PeriodicalArticleIsInPages\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (ArticleAuthor != ''):\n",
    "        if (',') in ArticleAuthor:\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "        else:\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(PeriodicalArticle, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(PeriodicalArticle, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(PeriodicalArticle, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(PeriodicalArticle, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(PeriodicalArticle, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (BOOKS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/books.csv')\n",
    "o = open('../OUTPUT_xml/books.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "## SI [0] id, [1] type, [2] author, [3] title, [6] collaborateurs, [8] placepub, [9] namepub, \n",
    "## SI [10] date, [11] pages, [12] comm interne, [13] Retranscrit, [15] digitized, [16] dans fonds CRLR  ##\n",
    "## NO [4] title_pub, [5] illustré par, [7] numéro, [14] website interest  ##\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 2000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasCollaborators\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasPublisher (PublisherTarget)\n",
    "    publisherName = row[9]\n",
    "    word_list = publisherName.replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    PublisherTarget = '_'.join(word_list)\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookHasSpecificPages\n",
    "    BookHasSpecificPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "                        \n",
    "                    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "        BookLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != ''):\n",
    "            BookLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and Date != ''):\n",
    "                BookLabelComplete = \"pub_\"+ArticleAuthor+Date\n",
    "            else:\n",
    "                if (PublicationHasTitle != '' and Date != ''):\n",
    "                    BookLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+Date\n",
    "\n",
    "    BookLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", BookLabelComplete)\n",
    "\n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    BookNS = ET.QName(NS_ROUD, \"Book\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    bookHasSpecificPagesNS = ET.QName(NS_ROUD, \"bookHasSpecificPages\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    hasPublisherNS = ET.QName(NS_ROUD, \"hasPublisher\")\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    Book = ET.Element(BookNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(Book, labelNS)\n",
    "    label.text = BookLabel\n",
    "    \n",
    "    ## -----------------------------> bookHasSpecificPages\n",
    "    if (BookHasSpecificPages!= ''):\n",
    "        bookHasSpecificPages = ET.SubElement(Book, bookHasSpecificPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookHasSpecificPages.text = BookHasSpecificPages\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(Book, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(Book, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublisher\n",
    "    if (publisherName != ''):\n",
    "        hasPublisher = ET.SubElement(Book, hasPublisherNS)\n",
    "        Publisher = ET.SubElement(hasPublisher, PublisherNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PublisherTarget})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(Book, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(Book, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(Book, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(Book, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(Book, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(Book, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (BOOK SECTION)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/booksections.csv')\n",
    "o = open('../OUTPUT_xml/booksections.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "## SI [0] id, [1] type, [2] author, [3] title, [4] title_pub, [6] collaborateurs, [7] volume, [8] placepub, [9] namepub, \n",
    "## SI [10] date, [11] pages, [12] comm interne, [13] Retranscrit, [15] digitized, [16] dans fonds CRLR  ##\n",
    "## NO [5] illustré par, [14] website interest  ##\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 3000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookSectionIsPartOf\n",
    "    BookSectionIsPartOf = row[4]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasCollaborators\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    ## -----------------------> isInBookVolume\n",
    "    IsInBookVolume = row[7]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasPublisher (PublisherTarget)\n",
    "    publisherName = row[9]\n",
    "    word_list = publisherName.replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    PublisherTarget = '_'.join(word_list)\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookSectionIsInPages\n",
    "    BookSectionIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "                        \n",
    "                    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and BookSectionIsPartOf != '' and Date != ''):\n",
    "        BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != ''):\n",
    "            BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+BookSectionIsPartOf\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "                BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "            else:\n",
    "                if (ArticleAuthor != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                    BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "                else:\n",
    "                    if (PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                        BookSectionLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "\n",
    "    BookSectionLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", BookSectionLabelComplete)\n",
    "\n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    BookSectionNS = ET.QName(NS_ROUD, \"BookSection\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    bookSectionIsInPagesNS = ET.QName(NS_ROUD, \"bookSectionIsInPages\")\n",
    "    bookSectionIsPartOfNS = ET.QName(NS_ROUD, \"bookSectionIsPartOf\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    isInBookVolumeNS = ET.QName(NS_ROUD, \"isInBookVolume\")\n",
    "    bookSectionHasPublisherNS = ET.QName(NS_ROUD, \"bookSectionHasPublisher\")\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    BookSection = ET.Element(BookSectionNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(BookSection, labelNS)\n",
    "    label.text = BookSectionLabel\n",
    "    \n",
    "    ## -----------------------------> bookSectionHasPublisher\n",
    "    if (publisherName != ''):\n",
    "        bookSectionHasPublisher = ET.SubElement(BookSection, bookSectionHasPublisherNS)\n",
    "        Publisher = ET.SubElement(bookSectionHasPublisher, PublisherNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PublisherTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> bookSectionIsInPages\n",
    "    if (BookSectionIsInPages!= ''):\n",
    "        bookSectionIsInPages = ET.SubElement(BookSection, bookSectionIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookSectionIsInPages.text = BookSectionIsInPages\n",
    "        \n",
    "    \n",
    "        \n",
    "    ## -----------------------------> BookSectionIsPartOf\n",
    "    if (BookSectionIsPartOf!= ''):\n",
    "        bookSectionIsPartOf = ET.SubElement(BookSection, bookSectionIsPartOfNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookSectionIsPartOf.text = BookSectionIsPartOf\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(BookSection, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(BookSection, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInBookVolume\n",
    "    if (IsInBookVolume != ''):\n",
    "        isInBookVolume = ET.SubElement(BookSection, isInBookVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInBookVolume.text = IsInBookVolume\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(BookSection, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(BookSection, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(BookSection, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(BookSection, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(BookSection, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(BookSection, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Stylo &agrave; bille, bleu Plume, noir Crayon, rouge Machine &agrave; &eacute;crire, rouge Premi&egrave;re lettre en rouge</p>\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "undefined entity: line 1, column 9 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/espadini/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-55-bf98e7654f8e>\"\u001b[0m, line \u001b[1;32m181\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    bla = ET.fromstring(hasOtherWritingTool_content)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/espadini/anaconda3/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m1314\u001b[0;36m, in \u001b[0;35mXML\u001b[0;36m\u001b[0m\n\u001b[0;31m    parser.feed(text)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m undefined entity: line 1, column 9\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (FICHES)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/fiches_DONT_TOUCH.csv')   ## should not be manipulated, because when changing the content of certain cells go to the next cell and the entire row is erroneous\n",
    "o = open('../OUTPUT_xml/fiches.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "##print(data[0:2])\n",
    "\n",
    "\n",
    "## [0] id, [1] titre, [2] archive_id, [3] oldcote, [4] cote, [5] ensemble_id, [6] type_id, [7] annotation, [8] support_id, \n",
    "## [9] support_info, [10] instrument_id, [11] color_id, [12] other_tool, [13] statut_id, [14] dates, [15] datation, \n",
    "## [16] datationlist_id, [17] datationcomment, [18] publie, [19] biblio_id, [20] auteurtraduit_id, [21]alreadydigitized, \n",
    "## [22] numerise_info, [23] commentaire, [24] photocopy, [25] resp_id\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "#### REGISTERING NAMESPACES\n",
    "###################################\n",
    "NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "NS_KNORARICHTEXT = \"http://example.com\"\n",
    "ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "ET.register_namespace(\"\", NS_KNORATEXT)\n",
    "\n",
    "\n",
    "###################################\n",
    "## DEFINE ELEMENTS WITH NS\n",
    "###################################\n",
    "ManuscriptNS = ET.QName(NS_ROUD, \"Manuscript\")\n",
    "labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "hasAnnotationNS = ET.QName(NS_ROUD, \"hasAnnotation\")\n",
    "hasDocumentTypeNS = ET.QName(NS_ROUD, \"hasDocumentType\")\n",
    "hasGeneticStageNS = ET.QName(NS_ROUD, \"hasGeneticStage\")\n",
    "hasOtherWritingToolNS = ET.QName(NS_ROUD, \"hasOtherWritingTool\")\n",
    "richtextNS = ET.QName(NS_KNORARICHTEXT, \"text\")\n",
    "hasPublicCommentNS = ET.QName(NS_ROUD, \"hasPublicComment\")\n",
    "hasSupportInfoNS = ET.QName(NS_ROUD, \"hasSupportInfo\")\n",
    "hasSupportTypeNS = ET.QName(NS_ROUD, \"hasSupportType\")\n",
    "hasTranslatedAuthorNS = ET.QName(NS_ROUD, \"hasTranslatedAuthor\")\n",
    "AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "hasWritingColorNS = ET.QName(NS_ROUD, \"hasWritingColor\")\n",
    "hasWritingToolNS = ET.QName(NS_ROUD, \"hasWritingTool\")\n",
    "isPhotocopyNS = ET.QName(NS_ROUD, \"isPhotocopy\")\n",
    "manuscriptHasDateNS = ET.QName(NS_ROUD, \"manuscriptHasDate\")\n",
    "manuscriptHasDateEstablishedComputableNS = ET.QName(NS_ROUD, \"manuscriptHasDateEstablishedComputable\")\n",
    "manuscriptHasDateEstablishedReadableNS = ET.QName(NS_ROUD, \"manuscriptHasDateEstablishedReadable\")\n",
    "manuscriptHasEditorialSetNS = ET.QName(NS_ROUD, \"manuscriptHasEditorialSet\")\n",
    "manuscriptHasInternalCommentNS = ET.QName(NS_ROUD, \"manuscriptHasInternalComment\")\n",
    "manuscriptHasOldShelfmarkNS = ET.QName(NS_ROUD, \"manuscriptHasOldShelfmark\")\n",
    "manuscriptHasPublishedReferenceNS = ET.QName(NS_ROUD, \"manuscriptHasPublishedReference\")\n",
    "PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "manuscriptHasShelfmarkNS = ET.QName(NS_ROUD, \"manuscriptHasShelfmark\")\n",
    "manuscriptHasTitleNS = ET.QName(NS_ROUD, \"manuscriptHasTitle\")\n",
    "manuscriptIsDigitizedNS = ET.QName(NS_ROUD, \"manuscriptIsDigitized\")\n",
    "manuscriptIsInArchiveNS = ET.QName(NS_ROUD, \"manuscriptIsInArchive\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[6:7]:\n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id + label\n",
    "    ficheid = 'fiche'+row[0] \n",
    "    ficheLabel = ficheid\n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasAnnotation\n",
    "    if (row[7] == 'oui'):\n",
    "        hasAnnotation_content = 'true'\n",
    "    else:\n",
    "        hasAnnotation_content = 'false'    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasDocumentType\n",
    "    documentType = row[6]\n",
    "    if (documentType == '1'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-manuscript'\n",
    "    if (documentType == '2'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-dactylo'\n",
    "    if (documentType == '3'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-imprime'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasGeneticStage\n",
    "    geneticStage = row[13]\n",
    "    if (geneticStage == '1'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-note'\n",
    "    if (geneticStage == '2'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-plan'\n",
    "    if (geneticStage == '3'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-brouillon'\n",
    "    if (geneticStage == '4'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-miseAuNet'\n",
    "    if (geneticStage == '5'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-manuscritDefinitif'\n",
    "    if (geneticStage == '6'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-epreuvesCorriges'\n",
    "    if (geneticStage == '7'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-originalCorrige'\n",
    "    if (geneticStage == '8'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-verifier'\n",
    "    if (geneticStage == '10'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-liste'\n",
    "    if (geneticStage == '11'):\n",
    "        hasGeneticStage_content = 'NULL'\n",
    "     \n",
    "    \n",
    "    ## -----------------------> hasOtherWritingTool\n",
    "    otherWritingTool = row[12]\n",
    "    if (otherWritingTool != ''):\n",
    "        hasOtherWritingTool_content = otherWritingTool\n",
    "        print(hasOtherWritingTool_content)\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## LABEL DA AGGIUSTARE !!\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Manuscript = ET.Element(ManuscriptNS, attrib={'id':ficheid}) \n",
    "    \n",
    "    label = ET.SubElement(Manuscript, labelNS)\n",
    "    label.text = ficheLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasAnnotation\n",
    "    hasAnnotation = ET.SubElement(Manuscript, hasAnnotationNS, attrib={'knoraType':'boolean_value'})\n",
    "    hasAnnotation.text = hasAnnotation_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasDocumentType\n",
    "    hasDocumentType = ET.SubElement(Manuscript, hasDocumentTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasDocumentType.text = hasDocumentType_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasGeneticStage\n",
    "    if (hasGeneticStage_content == 'NULL'):\n",
    "        pass\n",
    "    else:\n",
    "        hasGeneticStage = ET.SubElement(Manuscript, hasGeneticStageNS, attrib={'knoraType':'hlist_value'})\n",
    "        hasGeneticStage.text = hasGeneticStage_content\n",
    "        \n",
    "        \n",
    "    ## -----------------------------> hasOtherWritingTool\n",
    "    if (otherWritingTool != ''):\n",
    "        hasOtherWritingTool = ET.SubElement(Manuscript, hasOtherWritingToolNS, attrib={'knoraType':'richtext_value', 'mapping_id':'http://rdfh.ch/standoff/mappings/StandardMapping'})\n",
    "        richtext = ET.SubElement(hasOtherWritingTool, richtextNS, attrib={'xmlns':''})\n",
    "        bla = ET.fromstring(hasOtherWritingTool_content)\n",
    "        print(bla)\n",
    "        richtext.append(bla)\n",
    "    \n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(Manuscript, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html><head><title>Page Title</title></head><body bgcolor=\"#ffffff\">Hello, World!</body></html>'\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TEST SEMPLICE CREARE XML CON ELEMENTTREE\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "root = ET.Element(\"html\")\n",
    "\n",
    "head = ET.SubElement(root, \"head\")\n",
    "\n",
    "title = ET.SubElement(head, \"title\")\n",
    "title.text = \"Page Title\"\n",
    "\n",
    "body = ET.SubElement(root, \"body\")\n",
    "body.set(\"bgcolor\", \"#ffffff\")\n",
    "\n",
    "body.text = \"Hello, World!\"\n",
    "\n",
    "tree = ET.tostring(root)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TENTATIVI CON LXML, LASCIAMO PERDERE PERCHÈ NON RIESCO AD AGGIUNGERE NAMESPACES\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "xhtml = etree.Element(\"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}Publisher\")\n",
    "body = etree.SubElement(xhtml, \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}label\")\n",
    "body.text = \"Hello World\"\n",
    "\n",
    "\n",
    "root = etree.Element(\"root\")\n",
    "child2 = etree.SubElement(root, \"child2\")\n",
    "child3 = etree.SubElement(root, \"child3\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "tag = etree.QName('http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#', 'p0112-roud-oeuvres')\n",
    "root = etree.Element(\"{tag}root\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "\n",
    "print(etree.tostring(xhtml, pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "### LESS GOOD METHOD FOR CREATING XML FROM CSV\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers_bahbah.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## test cosa c'è nelle linee specificate\n",
    "## print(data[1:3])\n",
    "\n",
    "## FUNCTION THAT CREATES ITEM FROM CSV\n",
    "def convert_row(row):\n",
    "    ## ------->>>>>>> create id with first or first and last word of the publisher's name\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    return \"\"\"\n",
    "        <p0112-roud-oeuvres:Publisher id=\"edi_%s\">\n",
    "                <knoraXmlImport:label>edi_%s</knoraXmlImport:label>\n",
    "                <p0112-roud-oeuvres:publisherHasLocation knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasLocation>\n",
    "                <p0112-roud-oeuvres:publisherHasName knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasName>\n",
    "            </p0112-roud-oeuvres:Publisher>\n",
    "            \"\"\" % (words, row[1], row[0], row[1])\n",
    "\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "## WRITE ITEMS TO FILE, LOOP ON THE FUNCTION convert_row\n",
    "o.write('\\n'.join([convert_row(row) for row in data[1:]]))\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n",
    "\n",
    "\n",
    "## TO HAVE SHORTER ID (but rules are more complicated -also considering that they will be reused after for linking- and anyway there will be exceptions, so ...)\n",
    "##    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "##    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "##    if (word_list[0] == \"La\") or (word_list[0] == \"L\") or (word_list[0] == \"Les\") or (word_list[0] == \"Le\"): ## if the first word is ...\n",
    "##        if (word_list[1] == word_list[-1]): ## if the second and the last words are equal\n",
    "##            first_last_word = word_list[1]  ## take the second\n",
    "##        else:\n",
    "##            first_last_word = word_list[1]+'_'+word_list[-1]  ## otherwise take the second and the last\n",
    "##    else:    ## if the first word is NOT ...\n",
    "##        if (word_list[0] == word_list[-1]): ## if the first and the last words are equal\n",
    "##            first_last_word = word_list[0]  ## take the first\n",
    "##        else:\n",
    "##            first_last_word = word_list[0]+'_'+word_list[-1]   ## otherwise take the first and the last "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

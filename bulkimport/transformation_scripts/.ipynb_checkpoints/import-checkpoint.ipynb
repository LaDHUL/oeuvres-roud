{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SORT ACCORDING TO COLUMN\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "data = csv.reader(open('../INPUT_data/publishers.csv'))\n",
    "sortedlist = sorted(data, key=operator.itemgetter(1))    # 1 specifies according to first column we want to sort\n",
    "#now write the sorte result into new CSV file\n",
    "with open(\"../INPUT_data/publishers_sorted.csv\", \"w\") as f:\n",
    "  fileWriter = csv.writer(f, delimiter=',')\n",
    "  for row in sortedlist:\n",
    "      fileWriter.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PUBLISHERS\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "reader=csv.reader(open('../INPUT_data/publishers_sorted.csv', 'r'), delimiter=',')\n",
    "writer=csv.writer(open('../INPUT_data/publishers_sorted_distinct.csv', 'w'), delimiter=',')\n",
    "entries = set()\n",
    "\n",
    "for row in reader:\n",
    "   key = (row[0], row[1]) # instead of just the last name\n",
    "\n",
    "   if key not in entries:\n",
    "      writer.writerow(row)\n",
    "      entries.add(key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espadini/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PERIODICALS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/periodicals.csv\"\n",
    "file_name_output = \"../INPUT_data/periodicals_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espadini/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA AUTHORS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/authors.csv\"\n",
    "file_name_output = \"../INPUT_data/authors_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTHORS distinguish name and surname\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct.csv')\n",
    "o = open('../INPUT_data/authors_distinct_surname_name2.csv', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "writer = csv.writer(o, quoting=csv.QUOTE_ALL)\n",
    "for row in data[1:]:\n",
    "    author = row[0]\n",
    "    surname = author.partition(' ')[2] \n",
    "    name = author.partition(' ')[0]\n",
    "    new_author = [surname, name]\n",
    "    writer.writerow([new_author])\n",
    "\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### READ THE CSV (just to check)\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "for row in data[1:]:\n",
    "    \n",
    "    if (row[0] == ''):\n",
    "        print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PUBLISHERS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[1:]:\n",
    "    \n",
    "    publisherLocation = row[0] \n",
    "    publisherName = row[1]\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    publisherHasLocationNS = ET.QName(NS_ROUD, \"publisherHasLocation\")\n",
    "    publisherHasNameNS = ET.QName(NS_ROUD, \"publisherHasName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Publisher = ET.Element(PublisherNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Publisher, labelNS)\n",
    "    label.text = \"edi_\"+publisherName\n",
    "    \n",
    "    ## if row is empty, don't create element, otherwise the import will fail (of course only for properties that are not mandatory)\n",
    "    if (row[0] == ''):\n",
    "        print()\n",
    "    else:\n",
    "        publisherHasLocation = ET.SubElement(Publisher, publisherHasLocationNS, attrib={'knoraType':'richtext_value'})\n",
    "        publisherHasLocation.text = publisherLocation ## use variable defined with location of the publisher corresponding to first row\n",
    "    \n",
    "    publisherHasName = ET.SubElement(Publisher, publisherHasNameNS, attrib={'knoraType':'richtext_value'})\n",
    "    publisherHasName.text = publisherName  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Publisher, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PERIODICALS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/periodicals_distinct.csv')\n",
    "o = open('../OUTPUT_xml/periodicals.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    periodicalTitle = row[0] \n",
    "    labelPeriodicalTitle = row[0].replace('\"', '')  ## in label \" not accepted\n",
    "    word_list = re.split(', |\\(|/', labelPeriodicalTitle) ## split at comma, parenthesis or slash and take the first part (take the first part is below), using labelPeriodicalTitle where quotes have been already deleted\n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  ## replace accent with space and replace comma with nothing and split words\n",
    "    words = '_'.join(word_list) \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    periodicalHasTitleNS = ET.QName(NS_ROUD, \"periodicalHasTitle\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Periodical = ET.Element(PeriodicalNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Periodical, labelNS)\n",
    "    label.text = \"period_\"+labelPeriodicalTitle\n",
    "    periodicalHasTitle = ET.SubElement(Periodical, periodicalHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    periodicalHasTitle.text = periodicalTitle  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Periodical, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (AUTHORS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct_surname_name.csv')\n",
    "o = open('../OUTPUT_xml/authors.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    surname = row[1]\n",
    "    name = row[0]\n",
    "    #### for building id\n",
    "    if len(surname.split()) > 1:  ## if long name and surname\n",
    "        surnameid = '_'.join(re.split(' ', surname))\n",
    "    else:\n",
    "        surnameid = surname\n",
    "    if len(name.split()) > 1:\n",
    "        nameid = '_'.join(re.split(' ', name))\n",
    "    else:\n",
    "        nameid = name\n",
    "    if (row[0] == ''):  ## if author has only surname\n",
    "        authorid = (surnameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '') \n",
    "    else:\n",
    "        authorid = (surnameid+'_'+nameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '') \n",
    "   \n",
    "\n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    AuthorHasFamilyNameNS = ET.QName(NS_ROUD, \"authorHasFamilyName\")\n",
    "    AuthorHasGivenNameNS = ET.QName(NS_ROUD, \"authorHasGivenName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Author = ET.Element(AuthorNS, attrib={'id':authorid}) \n",
    "    label = ET.SubElement(Author, labelNS)\n",
    "    if (row[0] == ''):  ## if author has surname and name\n",
    "        label.text = \"aut_\"+surname\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "    else:\n",
    "        label.text = \"aut_\"+surname+\" \"+name\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "        authorHasGivenName = ET.SubElement(Author, AuthorHasGivenNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasGivenName.text = name  ## \n",
    "    \n",
    "    tree = ET.tostring(Author, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (ARTICLES)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/articles.csv')\n",
    "o = open('../OUTPUT_xml/articles.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 1000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> isPublishedInPeriodical\n",
    "    periodicalTitle = row[4].replace('\"', '')  ## all this copied from transformation to periodical above\n",
    "    word_list = re.split(', |\\(|/', periodicalTitle) \n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  \n",
    "    PeriodicalTarget = '_'.join(word_list) \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> IsInPeriodicalIssue\n",
    "    IsInPeriodicalIssueVolume = row[7]\n",
    "    if (',' in row[7]):\n",
    "        IsInPeriodicalIssue_split = re.split(', ',row[7])\n",
    "        IsInPeriodicalIssue = IsInPeriodicalIssue_split[0]\n",
    "        IsInPeriodicalVolume = IsInPeriodicalIssue_split[1].replace('-', ' et ')\n",
    "    else:\n",
    "        IsInPeriodicalVolumeOnly = row[7].replace('-', ' et ')\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> periodicalArticleIsInPages\n",
    "    PeriodicalArticleIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    PeriodicalArticleLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "    PeriodicalArticleLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", PeriodicalArticleLabelComplete)\n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',') in ArticleAuthor:\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "        ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "        ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "        ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "        with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "            csv_authors = csv.reader(authors_with_id)\n",
    "            ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "            for row in csv_authors:\n",
    "                if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                    AuthorTarget = row[2]\n",
    "                if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                    AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "        ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "        with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "            csv_authors = csv.reader(authors_with_id)\n",
    "            ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "            for row in csv_authors:\n",
    "                if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                    AuthorTargetSingle = row[2]\n",
    "                else:\n",
    "                    AuthorTarget = 'checkuno'\n",
    "            \n",
    "     ##  this creates list, while I want item\n",
    "        ##AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0] and ArticlesName in row[1]]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    PeriodicalArticleNS = ET.QName(NS_ROUD, \"PeriodicalArticle\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    isPublishedInPeriodicalNS = ET.QName(NS_ROUD, \"isPublishedInPeriodical\")\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    isInPeriodicalIssueNS = ET.QName(NS_ROUD, \"isInPeriodicalIssue\")\n",
    "    isInPeriodicalVolumeNS = ET.QName(NS_ROUD, \"isInPeriodicalVolume\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    periodicalArticleIsInPagesNS = ET.QName(NS_ROUD, \"periodicalArticleIsInPages\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    PeriodicalArticle = ET.Element(PeriodicalArticleNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(PeriodicalArticle, labelNS)\n",
    "    label.text = PeriodicalArticleLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(PeriodicalArticle, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(PeriodicalArticle, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInPeriodicalVolume  and  isInPeriodicalIssue\n",
    "    if (IsInPeriodicalIssueVolume != '' and IsInPeriodicalVolumeOnly == ''):\n",
    "        isInPeriodicalIssue = ET.SubElement(PeriodicalArticle, isInPeriodicalIssueNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalIssue.text = IsInPeriodicalIssue\n",
    "        isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalVolume.text = IsInPeriodicalVolume\n",
    "    else:   \n",
    "        if (IsInPeriodicalIssueVolume != ''):\n",
    "            isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "            isInPeriodicalVolume.text = IsInPeriodicalVolumeOnly\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isPublishedInPeriodical\n",
    "    isPublishedInPeriodical = ET.SubElement(PeriodicalArticle, isPublishedInPeriodicalNS)\n",
    "    Periodical = ET.SubElement(isPublishedInPeriodical, PeriodicalNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PeriodicalTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(PeriodicalArticle, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> periodicalArticleIsInPages\n",
    "    if (PeriodicalArticleIsInPages != ''):\n",
    "        periodicalArticleIsInPages = ET.SubElement(PeriodicalArticle, periodicalArticleIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        periodicalArticleIsInPages.text = PeriodicalArticleIsInPages\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    \n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(PeriodicalArticle, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(PeriodicalArticle, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(PeriodicalArticle, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(PeriodicalArticle, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(PeriodicalArticle, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (BOOKS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/books.csv')\n",
    "o = open('../OUTPUT_xml/books.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 1000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> isPublishedInPeriodical\n",
    "    periodicalTitle = row[4].replace('\"', '')  ## all this copied from transformation to periodical above\n",
    "    word_list = re.split(', |\\(|/', periodicalTitle) \n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  \n",
    "    PeriodicalTarget = '_'.join(word_list) \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> IsInPeriodicalIssue\n",
    "    IsInPeriodicalIssueVolume = row[7]\n",
    "    if (',' in row[7]):\n",
    "        IsInPeriodicalIssue_split = re.split(', ',row[7])\n",
    "        IsInPeriodicalIssue = IsInPeriodicalIssue_split[0]\n",
    "        IsInPeriodicalVolume = IsInPeriodicalIssue_split[1].replace('-', ' et ')\n",
    "    else:\n",
    "        IsInPeriodicalVolumeOnly = row[7].replace('-', ' et ')\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> periodicalArticleIsInPages\n",
    "    PeriodicalArticleIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    PeriodicalArticleLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "    PeriodicalArticleLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", PeriodicalArticleLabelComplete)\n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',') in ArticleAuthor:\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "        ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "        ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "        ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "        with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "            csv_authors = csv.reader(authors_with_id)\n",
    "            ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "            for row in csv_authors:\n",
    "                if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                    AuthorTarget = row[2]\n",
    "                if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                    AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "        ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "        with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "            csv_authors = csv.reader(authors_with_id)\n",
    "            ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "            for row in csv_authors:\n",
    "                if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                    AuthorTargetSingle = row[2]\n",
    "                else:\n",
    "                    AuthorTarget = 'checkuno'\n",
    "            \n",
    "     ##  this creates list, while I want item\n",
    "        ##AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0] and ArticlesName in row[1]]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    PeriodicalArticleNS = ET.QName(NS_ROUD, \"PeriodicalArticle\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    isPublishedInPeriodicalNS = ET.QName(NS_ROUD, \"isPublishedInPeriodical\")\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    isInPeriodicalIssueNS = ET.QName(NS_ROUD, \"isInPeriodicalIssue\")\n",
    "    isInPeriodicalVolumeNS = ET.QName(NS_ROUD, \"isInPeriodicalVolume\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    periodicalArticleIsInPagesNS = ET.QName(NS_ROUD, \"periodicalArticleIsInPages\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    PeriodicalArticle = ET.Element(PeriodicalArticleNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(PeriodicalArticle, labelNS)\n",
    "    label.text = PeriodicalArticleLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(PeriodicalArticle, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(PeriodicalArticle, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInPeriodicalVolume  and  isInPeriodicalIssue\n",
    "    if (IsInPeriodicalIssueVolume != '' and IsInPeriodicalVolumeOnly == ''):\n",
    "        isInPeriodicalIssue = ET.SubElement(PeriodicalArticle, isInPeriodicalIssueNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalIssue.text = IsInPeriodicalIssue\n",
    "        isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalVolume.text = IsInPeriodicalVolume\n",
    "    else:   \n",
    "        if (IsInPeriodicalIssueVolume != ''):\n",
    "            isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "            isInPeriodicalVolume.text = IsInPeriodicalVolumeOnly\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isPublishedInPeriodical\n",
    "    isPublishedInPeriodical = ET.SubElement(PeriodicalArticle, isPublishedInPeriodicalNS)\n",
    "    Periodical = ET.SubElement(isPublishedInPeriodical, PeriodicalNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PeriodicalTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(PeriodicalArticle, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> periodicalArticleIsInPages\n",
    "    if (PeriodicalArticleIsInPages != ''):\n",
    "        periodicalArticleIsInPages = ET.SubElement(PeriodicalArticle, periodicalArticleIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        periodicalArticleIsInPages.text = PeriodicalArticleIsInPages\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    \n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(PeriodicalArticle, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(PeriodicalArticle, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(PeriodicalArticle, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(PeriodicalArticle, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(PeriodicalArticle, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html><head><title>Page Title</title></head><body bgcolor=\"#ffffff\">Hello, World!</body></html>'\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TEST SEMPLICE CREARE XML CON ELEMENTTREE\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "root = ET.Element(\"html\")\n",
    "\n",
    "head = ET.SubElement(root, \"head\")\n",
    "\n",
    "title = ET.SubElement(head, \"title\")\n",
    "title.text = \"Page Title\"\n",
    "\n",
    "body = ET.SubElement(root, \"body\")\n",
    "body.set(\"bgcolor\", \"#ffffff\")\n",
    "\n",
    "body.text = \"Hello, World!\"\n",
    "\n",
    "tree = ET.tostring(root)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TENTATIVI CON LXML, LASCIAMO PERDERE PERCHÈ NON RIESCO AD AGGIUNGERE NAMESPACES\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "xhtml = etree.Element(\"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}Publisher\")\n",
    "body = etree.SubElement(xhtml, \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}label\")\n",
    "body.text = \"Hello World\"\n",
    "\n",
    "\n",
    "root = etree.Element(\"root\")\n",
    "child2 = etree.SubElement(root, \"child2\")\n",
    "child3 = etree.SubElement(root, \"child3\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "tag = etree.QName('http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#', 'p0112-roud-oeuvres')\n",
    "root = etree.Element(\"{tag}root\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "\n",
    "print(etree.tostring(xhtml, pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "### LESS GOOD METHOD FOR CREATING XML FROM CSV\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers_bahbah.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## test cosa c'è nelle linee specificate\n",
    "## print(data[1:3])\n",
    "\n",
    "## FUNCTION THAT CREATES ITEM FROM CSV\n",
    "def convert_row(row):\n",
    "    ## ------->>>>>>> create id with first or first and last word of the publisher's name\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    return \"\"\"\n",
    "        <p0112-roud-oeuvres:Publisher id=\"edi_%s\">\n",
    "                <knoraXmlImport:label>edi_%s</knoraXmlImport:label>\n",
    "                <p0112-roud-oeuvres:publisherHasLocation knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasLocation>\n",
    "                <p0112-roud-oeuvres:publisherHasName knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasName>\n",
    "            </p0112-roud-oeuvres:Publisher>\n",
    "            \"\"\" % (words, row[1], row[0], row[1])\n",
    "\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "## WRITE ITEMS TO FILE, LOOP ON THE FUNCTION convert_row\n",
    "o.write('\\n'.join([convert_row(row) for row in data[1:]]))\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n",
    "\n",
    "\n",
    "## TO HAVE SHORTER ID (but rules are more complicated -also considering that they will be reused after for linking- and anyway there will be exceptions, so ...)\n",
    "##    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "##    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "##    if (word_list[0] == \"La\") or (word_list[0] == \"L\") or (word_list[0] == \"Les\") or (word_list[0] == \"Le\"): ## if the first word is ...\n",
    "##        if (word_list[1] == word_list[-1]): ## if the second and the last words are equal\n",
    "##            first_last_word = word_list[1]  ## take the second\n",
    "##        else:\n",
    "##            first_last_word = word_list[1]+'_'+word_list[-1]  ## otherwise take the second and the last\n",
    "##    else:    ## if the first word is NOT ...\n",
    "##        if (word_list[0] == word_list[-1]): ## if the first and the last words are equal\n",
    "##            first_last_word = word_list[0]  ## take the first\n",
    "##        else:\n",
    "##            first_last_word = word_list[0]+'_'+word_list[-1]   ## otherwise take the first and the last "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SORT ACCORDING TO COLUMN\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "data = csv.reader(open('../INPUT_data/publishers.csv'))\n",
    "sortedlist = sorted(data, key=operator.itemgetter(1))    # 1 specifies according to first column we want to sort\n",
    "#now write the sorte result into new CSV file\n",
    "with open(\"../INPUT_data/publishers_sorted.csv\", \"w\") as f:\n",
    "  fileWriter = csv.writer(f, delimiter=',')\n",
    "  for row in sortedlist:\n",
    "      fileWriter.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PUBLISHERS\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "reader=csv.reader(open('../INPUT_data/publishers_sorted.csv', 'r'), delimiter=',')\n",
    "writer=csv.writer(open('../INPUT_data/publishers_sorted_distinct.csv', 'w'), delimiter=',')\n",
    "entries = set()\n",
    "\n",
    "for row in reader:\n",
    "   key = (row[0], row[1]) # instead of just the last name\n",
    "\n",
    "   if key not in entries:\n",
    "      writer.writerow(row)\n",
    "      entries.add(key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espadini/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PERIODICALS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/periodicals.csv\"\n",
    "file_name_output = \"../INPUT_data/periodicals_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### READ THE CSV (just to check)\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "for row in data[1:]:\n",
    "    \n",
    "    if (row[0] == ''):\n",
    "        print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PUBLISHERS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[1:]:\n",
    "    \n",
    "    publisherLocation = row[0] \n",
    "    publisherName = row[1]\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    publisherHasLocationNS = ET.QName(NS_ROUD, \"publisherHasLocation\")\n",
    "    publisherHasNameNS = ET.QName(NS_ROUD, \"publisherHasName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Publisher = ET.Element(PublisherNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Publisher, labelNS)\n",
    "    label.text = \"edi_\"+publisherName\n",
    "    \n",
    "    ## if row is empty, don't create element, otherwise the import will fail (of course only for properties that are not mandatory)\n",
    "    if (row[0] == ''):\n",
    "        print()\n",
    "    else:\n",
    "        publisherHasLocation = ET.SubElement(Publisher, publisherHasLocationNS, attrib={'knoraType':'richtext_value'})\n",
    "        publisherHasLocation.text = publisherLocation ## use variable defined with location of the publisher corresponding to first row\n",
    "    \n",
    "    publisherHasName = ET.SubElement(Publisher, publisherHasNameNS, attrib={'knoraType':'richtext_value'})\n",
    "    publisherHasName.text = publisherName  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Publisher, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PERIODICALS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/periodicals_distinct.csv')\n",
    "o = open('../OUTPUT_xml/periodicals.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[1:]:\n",
    "    \n",
    "    periodicalTitle = row[0] \n",
    "    labelPeriodicalTitle = row[0].replace('\"', '')  ## in label \" not accepted\n",
    "    word_list = re.split(', |\\(|/', row[0]) ## split at comma, parenthesis or slash and take the first part (take the first part is below)\n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  ## replace accent with space and replace comma with nothing and split words\n",
    "    words = '_'.join(word_list) \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    periodicalHasTitleNS = ET.QName(NS_ROUD, \"periodicalHasTitle\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Periodical = ET.Element(PeriodicalNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Periodical, labelNS)\n",
    "    label.text = \"period_\"+labelPeriodicalTitle\n",
    "    periodicalHasTitle = ET.SubElement(Periodical, periodicalHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    periodicalHasTitle.text = periodicalTitle  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Periodical, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html><head><title>Page Title</title></head><body bgcolor=\"#ffffff\">Hello, World!</body></html>'\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TEST SEMPLICE CREARE XML CON ELEMENTTREE\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "root = ET.Element(\"html\")\n",
    "\n",
    "head = ET.SubElement(root, \"head\")\n",
    "\n",
    "title = ET.SubElement(head, \"title\")\n",
    "title.text = \"Page Title\"\n",
    "\n",
    "body = ET.SubElement(root, \"body\")\n",
    "body.set(\"bgcolor\", \"#ffffff\")\n",
    "\n",
    "body.text = \"Hello, World!\"\n",
    "\n",
    "tree = ET.tostring(root)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TENTATIVI CON LXML, LASCIAMO PERDERE PERCHÈ NON RIESCO AD AGGIUNGERE NAMESPACES\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "xhtml = etree.Element(\"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}Publisher\")\n",
    "body = etree.SubElement(xhtml, \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}label\")\n",
    "body.text = \"Hello World\"\n",
    "\n",
    "\n",
    "root = etree.Element(\"root\")\n",
    "child2 = etree.SubElement(root, \"child2\")\n",
    "child3 = etree.SubElement(root, \"child3\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "tag = etree.QName('http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#', 'p0112-roud-oeuvres')\n",
    "root = etree.Element(\"{tag}root\")\n",
    "print(etree.tostring(root, pretty_print=True))\n",
    "\n",
    "\n",
    "\n",
    "print(etree.tostring(xhtml, pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SCRAPS - SCARTI\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "### LESS GOOD METHOD FOR CREATING XML FROM CSV\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers_bahbah.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## test cosa c'è nelle linee specificate\n",
    "## print(data[1:3])\n",
    "\n",
    "## FUNCTION THAT CREATES ITEM FROM CSV\n",
    "def convert_row(row):\n",
    "    ## ------->>>>>>> create id with first or first and last word of the publisher's name\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    return \"\"\"\n",
    "        <p0112-roud-oeuvres:Publisher id=\"edi_%s\">\n",
    "                <knoraXmlImport:label>edi_%s</knoraXmlImport:label>\n",
    "                <p0112-roud-oeuvres:publisherHasLocation knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasLocation>\n",
    "                <p0112-roud-oeuvres:publisherHasName knoraType=\"richtext_value\">%s</p0112-roud-oeuvres:publisherHasName>\n",
    "            </p0112-roud-oeuvres:Publisher>\n",
    "            \"\"\" % (words, row[1], row[0], row[1])\n",
    "\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "## WRITE ITEMS TO FILE, LOOP ON THE FUNCTION convert_row\n",
    "o.write('\\n'.join([convert_row(row) for row in data[1:]]))\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n",
    "\n",
    "\n",
    "## TO HAVE SHORTER ID (but rules are more complicated -also considering that they will be reused after for linking- and anyway there will be exceptions, so ...)\n",
    "##    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "##    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "##    if (word_list[0] == \"La\") or (word_list[0] == \"L\") or (word_list[0] == \"Les\") or (word_list[0] == \"Le\"): ## if the first word is ...\n",
    "##        if (word_list[1] == word_list[-1]): ## if the second and the last words are equal\n",
    "##            first_last_word = word_list[1]  ## take the second\n",
    "##        else:\n",
    "##            first_last_word = word_list[1]+'_'+word_list[-1]  ## otherwise take the second and the last\n",
    "##    else:    ## if the first word is NOT ...\n",
    "##        if (word_list[0] == word_list[-1]): ## if the first and the last words are equal\n",
    "##            first_last_word = word_list[0]  ## take the first\n",
    "##        else:\n",
    "##            first_last_word = word_list[0]+'_'+word_list[-1]   ## otherwise take the first and the last "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
